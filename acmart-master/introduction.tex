\section{Introduction}
\subsection{Motivation and Goal}
In many applications such as movie making, public security, and so on, virtual images are desired from sketches or several words describing the target object. Typically, an \textbf{interactive process} is employed to generate images, collect feedbacks, and then providing more information to keep updating the output image.

Possible directions:
\begin{enumerate}
	\item \textbf{SketchingAPhoto} Based on the image-image translation work, we can link hand-drawn sketch to edge map first, and then generate photo from the edge map. Step 1: retrieve similar edge maps by the input sketch; Step 2: generate images from the retrieved edge map.
	%
	\item \textbf{Face Image generation by text} while somebody is asked to describe a suspect, how to generate a photo/literary sketch to based on texts. How do people describe human faces. How do experts produce a sketch based on the words? 
\end{enumerate}


\subsection{Image-to-image translation}
Image-to-image translation has drawn a lot of attention recently, which aims to apply an image in one domain to generate a corresponding image in another, reserving shared concepts, objects or scenes in these two images.  

Generating a corresponding image from an input image can be reformulated as a conditional image generation problem which is conditioned on the input image. Previous works about conditional image generation problem focused on generating images from discrete labels~\cite{CGAN}, texts~\cite{Reed2016} and images.
\cite{pix2pix} firstly introduced the concept of image-to-image translation and trained a framework by paired images to handle multiply applications, such as labels to street scene, day to night, edge to photo and etc., only switching the training datasets.
%
\cite{CycleGAN, DiscoGAN, UNIT} extend the translation with difficultly and expensively achieved paired image datasets to unpaired image datasets, and they hugely widened the application to cover the scene where the desired outputs are highly complex or not even well-defined.

However, the previous works share a common shortage that the generated images always reserve the edge layout of the input images. 